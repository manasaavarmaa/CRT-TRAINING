{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def analyze_text_file(filepath):\n",
        "    try:\n",
        "        with open(filepath, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at {filepath}\")\n",
        "        return\n",
        "\n",
        "    # Tokenization using regular expressions (you can customize this)\n",
        "    tokens = re.findall(r'\\b\\w+\\b', text.lower())  # Find all words\n",
        "\n",
        "    # Calculate term frequency\n",
        "    term_frequencies = Counter(tokens)\n",
        "\n",
        "    # Display the top 5 most frequent tokens\n",
        "    print(\"Top 5 most frequent tokens:\")\n",
        "    for token, frequency in term_frequencies.most_common(5):\n",
        "        print(f\"{token}: {frequency}\")\n",
        "\n",
        "# Example usage:\n",
        "filepath = \"/content/file.txt\"  # Replace with your file path\n",
        "analyze_text_file(filepath)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fA99okFN70D",
        "outputId": "d194c3c1-5ba6-4895-b877-9ff272bb796e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 most frequent tokens:\n",
            "2023: 96\n",
            "0: 96\n",
            "07: 80\n",
            "the: 62\n",
            "positive: 53\n"
          ]
        }
      ]
    }
  ]
}